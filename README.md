# TheAnnotatedTransformer
Educational Transformer implementation based on Harvard's tutorial. Complete PyTorch code with Chinese annotations, interactive notebook, attention visualization, and translation examples. Perfect for learning NLP and deep learning concepts.

## ğŸš€ Features
- **Complete Transformer Implementation**: Full PyTorch implementation from "Attention Is All You Need"
- **Chinese Annotations**: Detailed Chinese comments for better understanding
- **Interactive Notebook**: Jupyter notebook with step-by-step explanations
- **Attention Visualization**: Visual representations of attention mechanisms
- **Translation Examples**: Real-world translation using Multi30k dataset

## ğŸ“ Project Structure
- `the_annotated_transformer.py` - Complete Transformer implementation
- `TheAnnotatedTransformer.ipynb` - Interactive Jupyter notebook
- `requirements.txt` - Dependencies and packages needed

## ğŸ¤– Model Files
**Note**: Pre-trained model files (*.pt) are not included in this repository due to their large size (each ~230MB). 

### How to Get the Models:
1. **Option 1**: Train your own models using the notebook
2. **Option 2**: Download pre-trained models (will be available on Hugging Face soon)
3. **Option 3**: Contact the repository owner for model files

### Model Files Available:
- `multi30k_model_00.pt` through `multi30k_model_07.pt` - Training checkpoints
- `multi30k_model_final.pt` - Final trained model
- `vocab.pt` - Vocabulary file

## ğŸ› ï¸ Installation
```bash
pip install -r requirements.txt
```

## ğŸ“š Usage
See `TheAnnotatedTransformer.ipynb` for detailed examples and explanations.

## ğŸ”¬ Training
The notebook includes complete training pipeline for Multi30k German-English translation task.

## ğŸ“„ License
This project follows the original Harvard Annotated Transformer license.

## ğŸ¤ Contributing
Feel free to submit issues and pull requests!

## ğŸ“ Contact
For questions about model files or project details, please open an issue.
220242544@seu.edu.cn